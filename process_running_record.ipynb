{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"process_running_record.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOob4DOLaqeSV1QqQRjXXn/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BlmZhNg3xHLK","colab_type":"text"},"source":["This notebook is intended to develop a script that will take as input a running record audio file and ground truth transcript, and output a transcript of the audio along with metadata that constitute a scoring of the running record."]},{"cell_type":"code","metadata":{"id":"zcFcxWrE0sVO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":629},"executionInfo":{"status":"ok","timestamp":1597419731915,"user_tz":240,"elapsed":18695,"user":{"displayName":"Carl Ehrett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GganZkK5Rhe5KtgqiYZsZbDuHckScP6emwuiFfP=s64","userId":"04089346461548986964"}},"outputId":"82af356c-885f-49e6-b9ce-1f8de95a254b"},"source":["!pip install ibm_watson\n","!pip install Fuzzy"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting ibm_watson\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dc/da/10f8774b319acdda29885931c01fae862622519bff492957c73b0ba84743/ibm-watson-4.5.0.tar.gz (370kB)\n","\u001b[K     |████████████████████████████████| 378kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (2.23.0)\n","Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (2.8.1)\n","Collecting websocket-client==0.48.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/a1/72ef9aa26cfe1a75cee09fc1957e4723add9de098c15719416a1ee89386b/websocket_client-0.48.0-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 8.5MB/s \n","\u001b[?25hCollecting ibm_cloud_sdk_core==1.5.1\n","  Downloading https://files.pythonhosted.org/packages/b7/f6/10d5271c807d73d236e6ae07b68035fed78b28b5ab836704d34097af3986/ibm-cloud-sdk-core-1.5.1.tar.gz\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (1.24.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python_dateutil>=2.5.3->ibm_watson) (1.15.0)\n","Collecting PyJWT>=1.7.1\n","  Downloading https://files.pythonhosted.org/packages/87/8b/6a9f14b5f781697e51259d81657e6048fd31a113229cf346880bb7545565/PyJWT-1.7.1-py2.py3-none-any.whl\n","Building wheels for collected packages: ibm-watson, ibm-cloud-sdk-core\n","  Building wheel for ibm-watson (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ibm-watson: filename=ibm_watson-4.5.0-cp36-none-any.whl size=364301 sha256=8509e7af99525d9602b6883f702251c930b94ce8d6c145201aeecb52c2a323cf\n","  Stored in directory: /root/.cache/pip/wheels/71/9a/0a/9b3ca8eca69bc5362eb04709a750b30055a9d27818fd0c9494\n","  Building wheel for ibm-cloud-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ibm-cloud-sdk-core: filename=ibm_cloud_sdk_core-1.5.1-cp36-none-any.whl size=44491 sha256=316c7298988cda2af7232eb3ca4388a1d124d9796f068980adaf645f1b6a4f8e\n","  Stored in directory: /root/.cache/pip/wheels/6a/42/50/f96888116b329578304f9dda4693cef6f3e76e18272d22cb6c\n","Successfully built ibm-watson ibm-cloud-sdk-core\n","Installing collected packages: websocket-client, PyJWT, ibm-cloud-sdk-core, ibm-watson\n","Successfully installed PyJWT-1.7.1 ibm-cloud-sdk-core-1.5.1 ibm-watson-4.5.0 websocket-client-0.48.0\n","Collecting Fuzzy\n","  Downloading https://files.pythonhosted.org/packages/ad/b0/210f790e81e3c9f86a740f5384c758ad6c7bc1958332cf64263a9d3cf336/Fuzzy-1.2.2.tar.gz\n","Building wheels for collected packages: Fuzzy\n","  Building wheel for Fuzzy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Fuzzy: filename=Fuzzy-1.2.2-cp36-cp36m-linux_x86_64.whl size=160959 sha256=028a0f62684f61d6b461eaa33ea1daf8df19652e3ec8823ae211daf4bd86382e\n","  Stored in directory: /root/.cache/pip/wheels/79/f7/14/b7e20855729780e85322529469b2d1eadfd940e83d981373cc\n","Successfully built Fuzzy\n","Installing collected packages: Fuzzy\n","Successfully installed Fuzzy-1.2.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DG8eu6330tEU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419732312,"user_tz":240,"elapsed":19086,"user":{"displayName":"Carl Ehrett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GganZkK5Rhe5KtgqiYZsZbDuHckScP6emwuiFfP=s64","userId":"04089346461548986964"}}},"source":["from ibm_watson import SpeechToTextV1\n","from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n","import fuzzy\n","import string"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"s0S6ZqT_tEwm","colab_type":"text"},"source":["# Class version\n","The below section produces a class structure for processing a running record.\n"]},{"cell_type":"code","metadata":{"id":"gB_EJhNeIFTX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1597419732313,"user_tz":240,"elapsed":19084,"user":{"displayName":"Carl Ehrett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GganZkK5Rhe5KtgqiYZsZbDuHckScP6emwuiFfP=s64","userId":"04089346461548986964"}}},"source":["# First define helper functions.\n","\n","# input string, get metaphone representations of each word in the string\n","def get_dmeta(string):\n","  \"\"\"\n","  Get double metaphone representation of a string. Written by Dillon Ranwala\n","  \"\"\"\n","  splitstring = string.split()\n","  stringlist = []\n","  for word in splitstring:\n","    stringlist.append(dmeta(word)[0])\n","  #decoding bytes into a unicode string for each word\n","  encoding = 'utf-8'\n","  bytes2str = []\n","  for byte in stringlist:\n","    b2str = byte.decode(encoding)\n","    bytes2str.append(b2str)\n","\n","  finalstr = ' '.join(bytes2str)\n","  return finalstr\n","\n","def levenshtein_distance_matrix(string1, string2, is_damerau=True):\n","  n1 = len(string1)\n","  n2 = len(string2)\n","  d = np.zeros((n1 + 1, n2 + 1), dtype=int)\n","  for i in range(n1 + 1):\n","      d[i, 0] = i\n","  for j in range(n2 + 1):\n","      d[0, j] = j\n","  for i in range(n1):\n","      for j in range(n2):\n","          if string1[i] == string2[j]:\n","              cost = 0\n","          else:\n","              cost = 1\n","          d[i+1, j+1] = min(d[i, j+1] + 1, # insert\n","                            d[i+1, j] + 1, # delete\n","                            d[i, j] + cost) # replace\n","          if is_damerau:\n","              if i > 0 and j > 0 and string1[i] == string2[j-1] and string1[i-1] == string2[j]:\n","                  d[i+1, j+1] = min(d[i+1, j+1], d[i-1, j-1] + cost) # transpose\n","  return d\n","\n","def location_tag(truth: str, hypothesis: str, is_damerau=True, mark_deletions = False):\n","  \"\"\"\n","  Returns an array the same length as hypothesis, where the ith entry is an \n","  integer value giving the index of the location of the ith element of \n","  hypothesis in truth. Elements of hypothesis that don't match truth are given\n","  value -1 if insertion, -2 if substition. \n","  Optionally, deletions can be marked as well, but this means the resulting \n","  output length won't match the hypothesis length.\n","\n","  Examples: for truth='kits' and hypothesis='kites', output=[0,1,2,-1,3]. \n","            for truth='kits' and hypothesis='mites', output=[-2,1,2,-1,3].\n","            for truth='kits' and hypothesis='mis', output=[-2,1,3].\n","  This code builds on code found at \n","  https://gist.github.com/jlherren/d97839b1276b9bd7faa930f74711a4b6.\n","  \"\"\"\n","  dist_matrix = _levenshtein_distance_matrix(truth, hypothesis, is_damerau)\n","  i, j = dist_matrix.shape\n","  i -= 1\n","  j -= 1\n","  ops = list()\n","  while i != -1 and j != -1:\n","      if is_damerau:\n","          if i > 1 and j > 1 and truth[i-1] == hypothesis[j-2] and truth[i-2] == hypothesis[j-1]:\n","              if dist_matrix[i-2, j-2] < dist_matrix[i, j]:\n","                  # ops.insert(0, ('transpose', i - 1, i - 2))\n","                  ops.insert(0, (i-2))\n","                  ops.insert(0, (i-1))\n","                  i -= 2\n","                  j -= 2\n","                  continue\n","      index = np.argmin([dist_matrix[i-1, j-1], dist_matrix[i, j-1], dist_matrix[i-1, j]])\n","      if index == 0:\n","          if dist_matrix[i, j] > dist_matrix[i-1, j-1]:\n","              ops.insert(0, -2)\n","          elif i>0: \n","              ops.insert(0, (i-1))\n","          i -= 1\n","          j -= 1\n","      elif index == 1:\n","          ops.insert(0, -1)\n","          j -= 1\n","      elif index == 2:\n","          if i+j>0:\n","            if mark_deletions:\n","              ops.insert(0, -3)\n","          i -= 1\n","  return ops\n","\n"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"moetl8pFtDnq","colab_type":"code","colab":{}},"source":["class Running_record:\n","  \"\"\"\n","  This class scores a running record audio file using a ground truth transcript.\n","  TODO: Figure out how to call a pre-trained WSTT model for transcription\n","  \"\"\"\n","\n","  def __init__(self, audio_filepath:str, wstt_credentials:str, ground_truth:str):\n","    self.audio_filepath = audio_filepath\n","    self.wstt_credentials = wstt_credentials\n","    self.ground_truth = ground_truth\n","\n","  def process_running_record(self):\n","    \"\"\"\n","    Call the class functions necessary to process the running record. I.e., get\n","    a WSTT transcript, convert that transcript to a pandas df, add a phonetic\n","    representation to that df, and then score the resulting df as a running\n","    record using the ground truth transcript.\n","    \"\"\"\n","    get_WSTT_transcript()\n","    convert_json_to_pddf()\n","    add_phonetic_representation()\n","    score_transcript()\n","\n","  def get_WSTT_transcript(self,\n","                          audio_filepath = None,\n","                          wstt_credentials = None):\n","    \"\"\"\n","    Use the Watson Speech to Text (WSTT) credentials stored in wstt_credentials to \n","    get a WSTT transcript of the audio file stored at audio_filepath.\n","\n","    Inputs\n","    ----------\n","    audio_filepath: str\n","      filepath of audio\n","    wstt_credentials: dict\n","      dict containing the following: \n","        authenticator -- authentification code for WSTT instance\n","        acoustic_id   -- acoustic model customization id\n","        language_id   -- language model customization id\n","\n","    Returns\n","    ----------\n","    transcript_json: str\n","      json format\n","\n","    It is recommended to use a customized, pretrained instance of WSTT.  \n","    \"\"\"\n","    # Define inputs\n","    if audio_filepath == None: audio_filepath = self.audio_filepath\n","    if wstt_credentials == None: wstt_credentials = self.wstt_credentials\n","\n","    # Authenticate into the Speech to Text service\n","    authenticator = IAMAuthenticator(wstt_credentials['authenticator'])\n","    speech_to_text = SpeechToTextV1(\n","      authenticator=authenticator\n","    )\n","    speech_to_text.set_service_url('https://stream.watsonplatform.net/speech-to-text/api')\n","\n","\n","    self.transcript_json = transcript_json\n","\n","  def convert_json_to_pddf(self, transcript_json = None):\n","    \"\"\"\n","    Take a JSON string output by WSTT and convert it into a pandas DF.\n","    \n","    Inputs\n","    ----------\n","    transcript_json: str\n","      json format, output from WSTT\n","      Default: self.transcript_json\n","\n","    Returns\n","    ----------\n","    transcript_df: pd.DataFrame\n","      A dataframe with the following columns:\n","      ==========  ==============================================================\n","      word_index  (ordinal that tells which word in the the transcript this is. \n","                   E.g., if the transcript gives two alternatives for the same \n","                   spoken word, there will be two rows sharing the same \n","                   word_index.)\n","      word        (self-explanatory)\n","      confidence  (WSTT returns confidence values for its multiple alternatives)\n","      start_time  (WSTT returns the time index for the beginning and end of a word)\n","      end_time    (WSTT returns the time index for the end of a word)\n","      ==========  ==============================================================\n","    \"\"\"\n","\n","    # Define inputs\n","    if transcript_json == None: transcript_json = self.transcript_json\n","    \n","    # Initialize column names of output DataFrame, and useful variables\n","    names = ['word_index','word','confidence','start_time','end_time']\n","    word_index = 0\n","    data = []\n","\n","    # Loop through the results, words, and word alternatives in the json\n","    # Collect the info we want in a list which will later become a pd.DataFrame\n","    for result in transcript_json['results']:\n","      for word in result['word_alternatives']:\n","        for alternative in word['alternatives']:\n","          entries = [word_index,\n","                    alternative['word'],\n","                    alternative['confidence'],\n","                    word['start_time'], \n","                    word['end_time']]\n","          data.append(dict(zip(names,entries)))\n","        word_index += 1\n","    \n","    # Convert to pd.DataFrame and save\n","    transcript_df = pd.DataFrame(data)\n","    self.transcript_df = transcript_df\n","\n","\n","  def convert_string_to_pddf(self, ground_truth = None):\n","    \"\"\"\n","    Take as input a string (the ground truth transcript) and convert it to a\n","    pandas data frame with a column corresponding to location in the text (e.g.\n","    first word has value 0), and column containing the words of the text.\n","\n","    Inputs\n","    ----------\n","    ground_truth: str\n","      String containing the ground truth transcript.\n","      Default: self.ground_truth\n","\n","    Returns\n","    ----------\n","    ground_truth_df: pd.DataFrame\n","      A dataframe with the following columns:\n","      ==========  ==============================================================\n","      word_index  (ordinal that tells which word in the the transcript this is. \n","      word        (self-explanatory)\n","      ==========  ==============================================================\n","    \"\"\"\n","\n","    # Define inputs\n","    if ground_truth == None: ground_truth = self.ground_truth\n","\n","    # Convert to lower, remove punctuation\n","    ground_truth = ground_truth.lower()\n","    exclude = set(string.punctuation)\n","    ground_truth = ''.join(ch for ch in ground_truth if ch not in exclude)\n","\n","    # Make into DataFrame\n","    ground_truth_df = pd.DataFrame(ground_truth.split(' '))\n","\n","    self.ground_truth_df = ground_truth_df\n","\n","\n","  def add_phonetic_representation(self, \n","                                  transcript_df = None, \n","                                  ground_truth_df = None):\n","    \"\"\"\n","    Take as input a pandas DF containing a column \"word\", and output the same DF \n","    with a new column added: \"phonetic\", which is a phonetic representation of \n","    \"word\".\n","\n","    Inputs\n","    ----------\n","    transcript_df: pd.DataFrame\n","      A dataframe containing the column \"word\"\n","      Default: self.transcript_df\n","\n","    Returns\n","    ----------\n","    transcript_df: pd.DataFrame\n","      A dataframe containing columns \"word\" and \"phonetic\".\n","    \"\"\"\n","\n","    # Define inputs\n","    if transcript_df == None: transcript_df = self.transcript_df\n","    if ground_truth_df == None: ground_truth_df = self.ground_truth_df\n","\n","    # Add phoneticization\n","    transcript_df['phonetic'] = transcript_df[['word']].apply(lambda x: get_dmeta(x[0]), axis=1)\n","    ground_truth_df['phonetic'] = ground_truth_df[['word']].apply(lambda x: get_dmeta(x[0]), axis=1)\n","\n","    # Update stored transcripts\n","    self.transcript_df = transcript_df\n","    self.ground_truth_df = ground_truth_df\n","\n","\n","  def score_transcript(self,\n","                       transcript_df = None,\n","                       ground_truth_df = None,\n","                       is_damerau = True):\n","    \"\"\"\n","    Take as input two dataframes each with column \"phonetic\", and use one of \n","    them as the ground truth with which to produce a running record score of the\n","    first.\n","\n","    Inputs\n","    ----------\n","    transcript_df: pd.DataFrame\n","      DataFrame with column \"phonetic\"; treated as hypothesis. \n","      Default: self.transcript_df\n","    self.ground_truth_df: pd.DataFrame\n","      DataFrame with column \"phonetic\"; treated as ground truth\n","    \n","    Returns\n","    ----------\n","    transcript_df: pd.DataFrame\n","      transcript_df with new column \"score\", which encodes the status of the\n","      hypothesis row as either correct, substitution, insertion, or repetition.\n","      # TODO: implement repetition tag.\n","      # TODO: make compatible with multiple hypotheses for each word.\n","    \"\"\"\n","\n","    # Define inputs\n","    if transcript_df == None: transcript_df = self.transcript_df\n","    if ground_truth_df == None: ground_truth_df = self.ground_truth_df\n","\n","    # Get location tags and \n","    score = location_tag(truth = ground_truth_df.phonetic,\n","                         hypothesis = transcript_df.phonetic,\n","                         is_damerau=is_damerau,\n","                         mark_deletions=False)\n","    transcript_df['score'] = score\n","\n","    self.transcript_df = transcript_df\n","\n","\n","\n","\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P3oSs2ErJ0Xi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1596640873299,"user_tz":240,"elapsed":316,"user":{"displayName":"Carl Ehrett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GganZkK5Rhe5KtgqiYZsZbDuHckScP6emwuiFfP=s64","userId":"04089346461548986964"}},"outputId":"ed47b6fd-cc0f-4814-ac9f-617356a4181f"},"source":["#scratch\n","rr = Running_record('audio','creds','truth')\n","rr.audio_filepath"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'audio'"]},"metadata":{"tags":[]},"execution_count":24}]}]}