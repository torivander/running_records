{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of running records class example.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_inqiy_fUtjC",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "This notebook is intended to develop a script that will take as input a running record audio file and ground truth transcript, and output a transcript of the audio along with metadata that constitute a scoring of the running record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXN-aCvuuu4j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "f2793490-6f0e-42c7-95d6-c4feeac0943c"
      },
      "source": [
        "!pip install ibm_watson\n",
        "!pip install Fuzzy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ibm_watson in /usr/local/lib/python3.6/dist-packages (4.7.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.0 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (2.23.0)\n",
            "Requirement already satisfied: ibm-cloud-sdk-core==1.7.3 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (1.7.3)\n",
            "Requirement already satisfied: websocket-client==0.48.0 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (0.48.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from ibm_watson) (2.8.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (2020.6.20)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0,>=2.0->ibm_watson) (3.0.4)\n",
            "Requirement already satisfied: PyJWT>=1.7.1 in /usr/local/lib/python3.6/dist-packages (from ibm-cloud-sdk-core==1.7.3->ibm_watson) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from websocket-client==0.48.0->ibm_watson) (1.15.0)\n",
            "Requirement already satisfied: Fuzzy in /usr/local/lib/python3.6/dist-packages (1.2.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pz8mlrcBuwEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from ibm_watson import SpeechToTextV1\n",
        "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import fuzzy\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znb7QWTuU_jg",
        "colab_type": "text"
      },
      "source": [
        "## Class version\n",
        "The below section produces a class structure for processing a running record."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4neWPpnu125",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First define helper functions.\n",
        "\n",
        "# input string, get metaphone representations of each word in the string\n",
        "def get_dmeta(string):\n",
        "  \"\"\"\n",
        "  Get double metaphone representation of a string. Written by Dillon Ranwala\n",
        "  \"\"\"\n",
        "  dmeta=fuzzy.DMetaphone()\n",
        "  splitstring = string.split()\n",
        "  stringlist = []\n",
        "  for word in splitstring:\n",
        "    stringlist.append(dmeta(word)[0])\n",
        "  #decoding bytes into a unicode string for each word\n",
        "  encoding = 'utf-8'\n",
        "  bytes2str = []\n",
        "  for byte in stringlist:\n",
        "    b2str = byte.decode(encoding)\n",
        "    bytes2str.append(b2str)\n",
        "\n",
        "  finalstr = ' '.join(bytes2str)\n",
        "  return finalstr\n",
        "\n",
        "def levenshtein_distance_matrix(string1, string2, is_damerau=True):\n",
        "  n1 = len(string1)\n",
        "  n2 = len(string2)\n",
        "  d = np.zeros((n1 + 1, n2 + 1), dtype=int)\n",
        "  for i in range(n1 + 1):\n",
        "      d[i, 0] = i\n",
        "  for j in range(n2 + 1):\n",
        "      d[0, j] = j\n",
        "  for i in range(n1):\n",
        "      for j in range(n2):\n",
        "          if string1[i] == string2[j]:\n",
        "              cost = 0\n",
        "          else:\n",
        "              cost = 1\n",
        "          d[i+1, j+1] = min(d[i, j+1] + 1, # insert\n",
        "                            d[i+1, j] + 1, # delete\n",
        "                            d[i, j] + cost) # replace\n",
        "          if is_damerau:\n",
        "              if i > 0 and j > 0 and string1[i] == string2[j-1] and string1[i-1] == string2[j]:\n",
        "                  d[i+1, j+1] = min(d[i+1, j+1], d[i-1, j-1] + cost) # transpose\n",
        "  return d\n",
        "\n",
        "def location_tag(truth: str, hypothesis: str, is_damerau=True, mark_deletions = False):\n",
        "  \"\"\"\n",
        "  Returns an array the same length as hypothesis, where the ith entry is an \n",
        "  integer value giving the index of the location of the ith element of \n",
        "  hypothesis in truth. Elements of hypothesis that don't match truth are given\n",
        "  value -1 if insertion, -2 if substition. \n",
        "  Optionally, deletions can be marked as well, but this means the resulting \n",
        "  output length won't match the hypothesis length.\n",
        "\n",
        "  Examples: for truth='kits' and hypothesis='kites', output=[0,1,2,-1,3]. \n",
        "            for truth='kits' and hypothesis='mites', output=[-2,1,2,-1,3].\n",
        "            for truth='kits' and hypothesis='mis', output=[-2,1,3].\n",
        "  This code builds on code found at \n",
        "  https://gist.github.com/jlherren/d97839b1276b9bd7faa930f74711a4b6.\n",
        "  \"\"\"\n",
        "  dist_matrix = levenshtein_distance_matrix(truth, hypothesis, is_damerau)\n",
        "  i, j = dist_matrix.shape\n",
        "  i -= 1\n",
        "  j -= 1\n",
        "  ops = list()\n",
        "  while i != -1 and j != -1:\n",
        "      if is_damerau:\n",
        "          if i > 1 and j > 1 and truth[i-1] == hypothesis[j-2] and truth[i-2] == hypothesis[j-1]:\n",
        "              if dist_matrix[i-2, j-2] < dist_matrix[i, j]:\n",
        "                  # ops.insert(0, ('transpose', i - 1, i - 2))\n",
        "                  ops.insert(0, (i-2))\n",
        "                  ops.insert(0, (i-1))\n",
        "                  i -= 2\n",
        "                  j -= 2\n",
        "                  continue\n",
        "      index = np.argmin([dist_matrix[i-1, j-1], dist_matrix[i, j-1], dist_matrix[i-1, j]])\n",
        "      if index == 0:\n",
        "          if dist_matrix[i, j] > dist_matrix[i-1, j-1]:\n",
        "              ops.insert(0, -2)\n",
        "          elif i>0: \n",
        "              ops.insert(0, (i-1))\n",
        "          i -= 1\n",
        "          j -= 1\n",
        "      elif index == 1:\n",
        "          ops.insert(0, -1)\n",
        "          j -= 1\n",
        "      elif index == 2:\n",
        "          if i+j>0:\n",
        "            if mark_deletions:\n",
        "              ops.insert(0, -3)\n",
        "          i -= 1\n",
        "  return ops"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LZ-CtcKvb4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Running_record:\n",
        "  \"\"\"\n",
        "  This class scores a running record audio file using a ground truth transcript.\n",
        "  TODO: Figure out how to call a pre-trained WSTT model for transcription\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, audio_filepath:str, wstt_credentials:str, ground_truth:str):\n",
        "    self.audio_filepath = audio_filepath\n",
        "    self.wstt_credentials = wstt_credentials\n",
        "    self.ground_truth = ground_truth\n",
        "\n",
        "  def process_running_record(self):\n",
        "    \"\"\"\n",
        "    Call the class functions necessary to process the running record. I.e., get\n",
        "    a WSTT transcript, convert that transcript to a pandas df, add a phonetic\n",
        "    representation to that df, and then score the resulting df as a running\n",
        "    record using the ground truth transcript.\n",
        "    \"\"\"\n",
        "    self.get_WSTT_transcript(audio_filepath,wstt_credentials)\n",
        "    self.convert_json_to_pddf()\n",
        "    self.convert_string_to_pddf()\n",
        "    self.add_phonetic_representation()\n",
        "    self.score_transcript()\n",
        "\n",
        "  def get_WSTT_transcript(self,\n",
        "                          audio_filepath = None,\n",
        "                          wstt_credentials = None):\n",
        "    \"\"\"\n",
        "    Use the Watson Speech to Text (WSTT) credentials stored in wstt_credentials to \n",
        "    get a WSTT transcript of the audio file stored at audio_filepath.\n",
        "\n",
        "    Inputs\n",
        "    ----------\n",
        "    audio_filepath: str\n",
        "      filepath of audio\n",
        "    wstt_credentials: dict\n",
        "      dict containing the following: \n",
        "        authenticator -- authentification code for WSTT instance\n",
        "        acoustic_id   -- acoustic model customization id\n",
        "        language_id   -- language model customization id\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    transcript_json: str\n",
        "      json format\n",
        "\n",
        "    It is recommended to use a customized, pretrained instance of WSTT.  \n",
        "    \"\"\"\n",
        "    # Define inputs\n",
        "    if audio_filepath == None: audio_filepath = self.audio_filepath\n",
        "    if wstt_credentials == None: wstt_credentials = self.wstt_credentials\n",
        "\n",
        "    # Authenticate into the Speech to Text service\n",
        "    authenticator = IAMAuthenticator(wstt_credentials['authenticator'])\n",
        "    speech_to_text = SpeechToTextV1(\n",
        "      authenticator=authenticator\n",
        "    )\n",
        "    speech_to_text.set_service_url('https://stream.watsonplatform.net/speech-to-text/api')\n",
        "\n",
        "    with open(audio_filepath, 'rb') as audio_file:\n",
        "      transcript_json = speech_to_text.recognize(\n",
        "          audio=audio_file,\n",
        "          acoustic_customization_id=wstt_credentials['acoustic_id'],\n",
        "          content_type='audio/mp3',\n",
        "          word_alternatives_threshold=0,\n",
        "          speaker_labels=False\n",
        "      ).get_result()\n",
        "\n",
        "\n",
        "    self.transcript_json = transcript_json\n",
        "\n",
        "  def convert_json_to_pddf(self, transcript_json = None):\n",
        "    \"\"\"\n",
        "    Take a JSON string output by WSTT and convert it into a pandas DF.\n",
        "    \n",
        "    Inputs\n",
        "    ----------\n",
        "    transcript_json: str\n",
        "      json format, output from WSTT\n",
        "      Default: self.transcript_json\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    transcript_df: pd.DataFrame\n",
        "      A dataframe with the following columns:\n",
        "      ==========  ==============================================================\n",
        "      word_index  (ordinal that tells which word in the the transcript this is. \n",
        "                   E.g., if the transcript gives two alternatives for the same \n",
        "                   spoken word, there will be two rows sharing the same \n",
        "                   word_index.)\n",
        "      word        (self-explanatory)\n",
        "      confidence  (WSTT returns confidence values for its multiple alternatives)\n",
        "      start_time  (WSTT returns the time index for the beginning and end of a word)\n",
        "      end_time    (WSTT returns the time index for the end of a word)\n",
        "      ==========  ==============================================================\n",
        "    \"\"\"\n",
        "\n",
        "    # Define inputs\n",
        "    if transcript_json == None: transcript_json = self.transcript_json\n",
        "    \n",
        "    # Initialize column names of output DataFrame, and useful variables\n",
        "    names = ['word_index','word','confidence','start_time','end_time']\n",
        "    word_index = 0\n",
        "    data = []\n",
        "\n",
        "    # Loop through the results, words, and word alternatives in the json\n",
        "    # Collect the info we want in a list which will later become a pd.DataFrame\n",
        "    for result in transcript_json['results']:\n",
        "      for word in result['word_alternatives']:\n",
        "        for alternative in word['alternatives']:\n",
        "          entries = [word_index,\n",
        "                    alternative['word'],\n",
        "                    alternative['confidence'],\n",
        "                    word['start_time'], \n",
        "                    word['end_time']]\n",
        "          data.append(dict(zip(names,entries)))\n",
        "        word_index += 1\n",
        "    \n",
        "    # Convert to pd.DataFrame and save\n",
        "    transcript_df = pd.DataFrame(data)\n",
        "    self.transcript_df = transcript_df\n",
        "\n",
        "\n",
        "  def convert_string_to_pddf(self, ground_truth = None):\n",
        "    \"\"\"\n",
        "    Take as input a string (the ground truth transcript) and convert it to a\n",
        "    pandas data frame with a column corresponding to location in the text (e.g.\n",
        "    first word has value 0), and column containing the words of the text.\n",
        "\n",
        "    Inputs\n",
        "    ----------\n",
        "    ground_truth: str\n",
        "      String containing the ground truth transcript.\n",
        "      Default: self.ground_truth\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    ground_truth_df: pd.DataFrame\n",
        "      A dataframe with the following columns:\n",
        "      ==========  ==============================================================\n",
        "      word_index  (ordinal that tells which word in the the transcript this is. \n",
        "      word        (self-explanatory)\n",
        "      ==========  ==============================================================\n",
        "    \"\"\"\n",
        "\n",
        "    # Define inputs\n",
        "    if ground_truth == None: ground_truth = self.ground_truth\n",
        "\n",
        "    # Convert to lower, remove punctuation\n",
        "    ground_truth = ground_truth.lower()\n",
        "    exclude = set(string.punctuation)\n",
        "    ground_truth = ''.join(ch for ch in ground_truth if ch not in exclude)\n",
        "\n",
        "    # Make into DataFrame\n",
        "    ground_truth_df = pd.DataFrame(ground_truth.split(' '),columns=['word'])\n",
        "    #ground_truth_df.rename(columns={\"0\": 'word'},inplace=True)\n",
        "\n",
        "    self.ground_truth_df = ground_truth_df\n",
        "\n",
        "\n",
        "  def add_phonetic_representation(self, \n",
        "                                  transcript_df = None, \n",
        "                                  ground_truth_df = None):\n",
        "    \"\"\"\n",
        "    Take as input a pandas DF containing a column \"word\", and output the same DF \n",
        "    with a new column added: \"phonetic\", which is a phonetic representation of \n",
        "    \"word\".\n",
        "\n",
        "    Inputs\n",
        "    ----------\n",
        "    transcript_df: pd.DataFrame\n",
        "      A dataframe containing the column \"word\"\n",
        "      Default: self.transcript_df\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "    transcript_df: pd.DataFrame\n",
        "      A dataframe containing columns \"word\" and \"phonetic\".\n",
        "    \"\"\"\n",
        "\n",
        "    # Define inputs\n",
        "    if transcript_df == None: transcript_df = self.transcript_df\n",
        "    if ground_truth_df == None: ground_truth_df = self.ground_truth_df\n",
        "\n",
        "    # Add phoneticization\n",
        "    transcript_df['phonetic'] = transcript_df[['word']].apply(lambda x: get_dmeta(x[0]), axis=1)\n",
        "    ground_truth_df['phonetic'] = ground_truth_df[['word']].apply(lambda x: get_dmeta(x[0]), axis=1)\n",
        "\n",
        "    # Update stored transcripts\n",
        "    self.transcript_df = transcript_df\n",
        "    self.ground_truth_df = ground_truth_df\n",
        "\n",
        "\n",
        "  def score_transcript(self,\n",
        "                       transcript_df = None,\n",
        "                       ground_truth_df = None,\n",
        "                       is_damerau = True):\n",
        "    \"\"\"\n",
        "    Take as input two dataframes each with column \"phonetic\", and use one of \n",
        "    them as the ground truth with which to produce a running record score of the\n",
        "    first.\n",
        "\n",
        "    Inputs\n",
        "    ----------\n",
        "    transcript_df: pd.DataFrame\n",
        "      DataFrame with column \"phonetic\"; treated as hypothesis. \n",
        "      Default: self.transcript_df\n",
        "    self.ground_truth_df: pd.DataFrame\n",
        "      DataFrame with column \"phonetic\"; treated as ground truth\n",
        "    \n",
        "    Returns\n",
        "    ----------\n",
        "    transcript_df: pd.DataFrame\n",
        "      transcript_df with new column \"score\", which encodes the status of the\n",
        "      hypothesis row as either correct, substitution, insertion, or repetition.\n",
        "      # TODO: implement repetition tag.\n",
        "      # TODO: make compatible with multiple hypotheses for each word.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define inputs\n",
        "    if transcript_df == None: transcript_df = self.transcript_df\n",
        "    if ground_truth_df == None: ground_truth_df = self.ground_truth_df\n",
        "\n",
        "    # Get location tags and adding a score\n",
        "    score = location_tag(truth = ground_truth_df.phonetic,\n",
        "                         hypothesis = transcript_df.phonetic,\n",
        "                         is_damerau=is_damerau,\n",
        "                         mark_deletions=False)\n",
        "    transcript_df['score'] = score\n",
        "\n",
        "    # Grouping together word alternatives when none are correct (leaves only the one with the highest confidence)\n",
        "    transcript_df['wrong_tag'] = np.where(transcript_df['score'] < 0, True,False)\n",
        "    transcript_df = transcript_df.groupby(['word_index','wrong_tag'], group_keys=False).apply(lambda x: x.loc[x.confidence.idxmax()])\n",
        "   \n",
        "    transcript_df = transcript_df.reset_index(level=1, drop=True)   \n",
        "\n",
        "    # Finds remaining word alternatives and labeling them with a temp column\n",
        "    transcript_df['match'] = transcript_df.word_index.eq(transcript_df.word_index.shift())\n",
        "    transcript_df['match2'] = transcript_df.word_index.eq(transcript_df.word_index.shift(-1))\n",
        "    transcript_df['dup'] = transcript_df.match | transcript_df.match2\n",
        "\n",
        "    # Removes any remaining word alternatives if one of them is correct\n",
        "    transcript_df = transcript_df.loc[~((transcript_df['dup'] == True) &(transcript_df['score']<0))]\n",
        "    \n",
        "    transcript_df = transcript_df.drop(columns=['match','match2','dup','word_index','wrong_tag']).reset_index()\n",
        "\n",
        "    self.transcript_df = transcript_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTpmHo5TLXr",
        "colab_type": "text"
      },
      "source": [
        "Testing Class Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjJ2HmaWwmml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rr = Running_record(audio_filepath,'7IocK75SM9h9GOACa6jlbNJRqfW5EKkFQ8fbK6kKJZva',ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV3lxqUX1cyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rr.__init__(audio_filepath,wstt_credentials['authenticator'],ground_truth)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceV7sd4qLFZP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rr.process_running_record()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKYDJDwGUlV4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "5b086f04-5ed7-4f45-9cd6-d66cc012c92e"
      },
      "source": [
        "rr.transcript_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_index</th>\n",
              "      <th>word</th>\n",
              "      <th>confidence</th>\n",
              "      <th>start_time</th>\n",
              "      <th>end_time</th>\n",
              "      <th>phonetic</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>please</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.10</td>\n",
              "      <td>PLS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>call</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.13</td>\n",
              "      <td>1.41</td>\n",
              "      <td>KL</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Stella</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.41</td>\n",
              "      <td>1.97</td>\n",
              "      <td>STL</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>ask</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.49</td>\n",
              "      <td>2.81</td>\n",
              "      <td>ASK</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>her</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.81</td>\n",
              "      <td>3.00</td>\n",
              "      <td>HR</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>66</td>\n",
              "      <td>Wednesday</td>\n",
              "      <td>1.0</td>\n",
              "      <td>39.91</td>\n",
              "      <td>40.52</td>\n",
              "      <td>ATNS</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>at</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40.66</td>\n",
              "      <td>41.01</td>\n",
              "      <td>AT</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>68</td>\n",
              "      <td>the</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.16</td>\n",
              "      <td>41.35</td>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>69</td>\n",
              "      <td>train</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.35</td>\n",
              "      <td>41.65</td>\n",
              "      <td>TRN</td>\n",
              "      <td>67</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>70</td>\n",
              "      <td>station</td>\n",
              "      <td>1.0</td>\n",
              "      <td>41.65</td>\n",
              "      <td>42.13</td>\n",
              "      <td>STXN</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>71 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    word_index       word  confidence  start_time  end_time phonetic  score\n",
              "0            0     please         1.0        0.52      1.10      PLS      0\n",
              "1            1       call         1.0        1.13      1.41       KL      1\n",
              "2            2     Stella         1.0        1.41      1.97      STL      2\n",
              "3            3        ask         1.0        2.49      2.81      ASK      3\n",
              "4            4        her         1.0        2.81      3.00       HR      4\n",
              "..         ...        ...         ...         ...       ...      ...    ...\n",
              "66          66  Wednesday         1.0       39.91     40.52     ATNS     64\n",
              "67          67         at         1.0       40.66     41.01       AT     65\n",
              "68          68        the         1.0       41.16     41.35        0     66\n",
              "69          69      train         1.0       41.35     41.65      TRN     67\n",
              "70          70    station         1.0       41.65     42.13     STXN     68\n",
              "\n",
              "[71 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5X5lJFbqji4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}